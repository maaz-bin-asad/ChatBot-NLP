{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DialogSystem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJQQpJkE0UM4",
        "colab_type": "text"
      },
      "source": [
        "Importing and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTB77jPM_QbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import warnings   #importing the libaries\n",
        "import string\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import io\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "warnings.filterwarnings('ignore')\n",
        "f=open('global.txt')\n",
        "raw=f.read()\n",
        "raw=raw.lower()\n",
        "set_tokens=nltk.sent_tokenize(raw)\n",
        "word_tokenize=nltk.word_tokenize(raw)\n",
        "lemmer=nltk.stem.WordNetLemmatizer()\n",
        "def lemma(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punc=dict((ord(punct),None) for punct in string.punctuation)  #preprocessing the corpus\n",
        "def normalize(text):\n",
        "  re.sub('^[a-zA-Z]','',text)\n",
        "  return lemma(nltk.word_tokenize(text.lower().translate(remove_punc)))\n",
        "greet=(\"hello\",\"hi\",\"hola\",\"hey there\",\"hey mate\",\"how are you\",'hey')\n",
        "greet_response=['hi','hey there','nice to meet you developer']\n",
        "def greeting(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in greet:\n",
        "      return random.choice(greet_response)\n",
        "def response(user):\n",
        "  chat=''\n",
        "  set_tokens.append(user)\n",
        "  vector=TfidfVectorizer(tokenizer=normalize , stop_words='english')   #vectorizing the corpus\n",
        "  vector_final=vector.fit_transform(set_tokens)\n",
        "  vals=cosine_similarity(vector_final[-1],vector_final)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat=vals.flatten()\n",
        "  flat.sort()\n",
        "  req=flat[-2]\n",
        "  if req==0:\n",
        "    chat=chat+\"I am sorry ! Could not understand\"\n",
        "  else:\n",
        "    chat+=set_tokens[idx]\n",
        "    return chat\n",
        "flag=True\n",
        "print(\"I am a dialog system providing some facts about our country India\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtTG3tDC0HSB",
        "colab_type": "text"
      },
      "source": [
        "Prepare for output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEOCb7Gu0Eyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while(flag==True):\n",
        "    user=input()\n",
        "    user=user.lower()\n",
        "    if user!=\"bye\":\n",
        "      if user=='thanks' or user =='thank you':\n",
        "        flag=False                                                                                 #preparing to chat\n",
        "        print(\"You are welcome\")\n",
        "      else:\n",
        "        if greeting(user)!=None:\n",
        "          print(\"IndianBot:  \"+greeting(user))\n",
        "        else:\n",
        "          print(\"IndianBot:  \",end='')\n",
        "          print(response(user))\n",
        "          set_tokens.remove(user)\n",
        "    else:\n",
        "      flag=False\n",
        "      print(\"ChatBot: BYE See you soon buddy\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKXXQYKrVeUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}